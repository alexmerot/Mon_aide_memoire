[["index.html", "Aide-mémoire : Analyses de données &amp; Cartographie sur R Introduction Prérequis Quelques configurations globales", " Aide-mémoire : Analyses de données &amp; Cartographie sur R Alexis Mérot Modifié le : 2020-11-17 Introduction Cet aide-mémoire n’est pour l’instant qu’un brouillon et un terrain de jeu pour pratiquer R, RMarkdown, l’HTML et le CSS. Il est donc loin d’être complet et l’écriture est pour l’instant très succincte. Le fond et la forme pourront donc être modifiés n’importe quand. Bien que ce soit public, ce projet est donc pour l’instant personnel et me permet de revenir facilement sur des notions dont j’ai besoin. Cet aide-mémoire est un ensemble de notes écrites en R Markdown (Allaire et al. 2020) et via le package bookdown. Ces notes s’accumuleront au fur et à mesure de mon apprentissage des différents outils et concepts dont j’ai besoin pour les analyses de données et en général pour la programmation avec R. Cela me permet de mieux les comprendre, les mémoriser, ainsi que de m’entraîner à les partager. Ceci n’est que la graine d’un projet de blog pour répertorier mes futurs projets et pouvoir partager mes connaissances portant sur le monde de R ainsi que sur l’écologie et la biologie de la conservation. Toutes les sources qui m’ont été utiles pour acquérir ces connaissances seront accessibles dans les références bibliographiques ou dans les ressources Internet à la fin des chapitres. Prérequis La version minimale de R utilisée ici est une version ≥ 4.0. Cette version contient des changements majeurs tels que la spécification de chaînes de caractères brutes (utile notamment pour les expressions régulières) ou la valeur par défaut FALSE de l’option stringAsFactors. Les sections de code pourraient donc ne pas fonctionner si la version utilisée est inférieure à la 4.0. Pour une information complète sur la session R utilisée ici, il faut se référer à la section Session info. Quelques configurations globales Chargement des packages utiles sur l’ensemble de l’aide-mémoire : library(&quot;ggplot2&quot;) # Visualisation des données basée sur &quot;The Grammar of graphics&quot; library(&quot;ggrepel&quot;) # Permet un meilleur affichage des étiquettes library(&quot;ggforce&quot;) # Extension de ggplot2 pour de nouveaux geom_* library(&quot;ggthemes&quot;) # Ajoute d&#39;autres thèmes à ggplot2 library(&quot;patchwork&quot;) # Permet de combiner facilement les graphiques library(&quot;dplyr&quot;) # Permet la manipulation des données library(&quot;glue&quot;) # Interprétation des chaînes de caractères littérales library(&quot;reactable&quot;) # Création des tableaux interactifs (HTML seulement) Configuration du thème par défaut des tableaux via le package reactable : options(reactable.theme = reactableTheme( color = &quot;hsl(233, 9%, 87%)&quot;, backgroundColor = &quot;hsl(233, 9%, 19%)&quot;, borderColor = &quot;hsl(233, 9%, 22%)&quot;, stripedColor = &quot;hsl(233, 12%, 22%)&quot;, highlightColor = &quot;hsl(233, 12%, 24%)&quot;, inputStyle = list(backgroundColor = &quot;hsl(233, 9%, 25%)&quot;), selectStyle = list(backgroundColor = &quot;hsl(233, 9%, 25%)&quot;), pageButtonHoverStyle = list(backgroundColor = &quot;hsl(233, 9%, 25%)&quot;), pageButtonActiveStyle = list(backgroundColor = &quot;hsl(233, 9%, 28%)&quot;) ) ) # Paramètres par défaut. my_reactable &lt;- function( data, height = 650, filterable = TRUE, defaultPageSize = 5, minRows = 5, highlight = TRUE, rownames = TRUE, striped = TRUE, pagination = FALSE, defaultColDef = colDef(na = &quot;NA&quot;, align = &quot;center&quot;), style = list(fontSize = &quot;10px&quot;), ... ) { reactable( data, height = height, filterable = filterable, defaultPageSize = defaultPageSize, minRows = minRows, highlight = highlight, rownames = rownames, striped = striped, pagination = pagination, defaultColDef = defaultColDef, style = style, ... ) } Références "],["rmarkdown.html", "1 R Markdown, Bookdown &amp; Blogdown 1.1 Pourquoi R Markdown ? Liste de ressources Internet utiles", " 1 R Markdown, Bookdown &amp; Blogdown Work In Progress 1.1 Pourquoi R Markdown ? R Markdown désigne un format de fichier (à l’extension .Rmd) et plus globalement le framework utilisé pour créer plus facilement des documents (généralement scientifiques) automatisés. Ces documents peuvent ainsi être totalement reproductibles et plusieurs formats d’exportation (statiques ou dynamiques) sont supportés. Le fichier est écrit via le langage Markdown et des sections de code R peuvent y être insérées facilement (ainsi que du code écrit via d’autres langages tels que Python ou SQL). Cela offre une syntaxe facile à lire et à écrire tout en permettant de générer un document structuré et élégant. Pour que cela fonctionne, R Markdown est lié à deux packages : knitr et le convertisseur universel de document pandoc (Fig. 1.1). Le package knitr permet la création, à partir du fichier .Rmd, d’un fichier au format .md contenant le code et sa sortie. Ce fichier est alors converti dans le format d’exportation voulu via pandoc (.html, .pdf, etc). Pour une configuration plus poussée de la mise en page, selon le format d’exportation utilisé il est préférable d’avoir quelques bases de HTML/CSS et de \\(\\LaTeX\\). Néanmoins, avec les bons mots-clés il est facile de trouver des réponses aux problèmes rencontrés via votre moteur de recherche préféré (généralement, au moins une autre personne s’est arrachée sa belle chevelure sur un problème similaire au vôtre, s’en est plaint sur un forum équivalent à Stackoverflow, puis s’est vue éventuellement répondre un trollesque « RTFM »). Néanmoins, la prise en main de RMarkdown est plutôt facile et sa constante évolution due à sa communauté fait que la mise en forme des documents est de plus en plus simple. Figure 1.1: Diagramme montrant le processus de création de documents à partir de RMarkdown. Pour ne pas paraphraser tout l’excellent guide de Xie, Allaire, et Grolemund (2018), je vous invite à lire leur livre : https://bookdown.org/yihui/rmarkdown/, ainsi que leur nouveau livre R Markdown Cookbook. Liste de ressources Internet utiles R Markdown : Vue d’ensemble de R Markdown Cours sur la communication avec R Markdown Comment utiliser R Markdown comme base pour le développement de packages bien organisés Quelques trucs et astuces sur R Markdown Comment donner du peps à mon document RMD Un autre guide de R Markdown Guide complet de R Markdown Nouveau guide de R Markdown (en cours d’écriture) Création d’un template R Markdown Bookdown : Site officiel de bookdown Guide complet de bookdown Extension à bookdown : bookdownplus Guide en français de bookdown Introduction en français à bookdown Blogdown : Guide complet sur blogdown Court tutoriel d’introduction sur R Markdown, bookdown et blogdown Guide pour le package knitr Options valables pour les chunks de code et le package knitr Références "],["data-analysis.html", "2 Extraction/importation, nettoyage &amp; manipulation des données 2.1 Extraction de données provenant d’un PDF 2.2 Récupération de données provenant du web : le web scraping Liste de ressources Internet utiles", " 2 Extraction/importation, nettoyage &amp; manipulation des données Work In Progress 2.1 Extraction de données provenant d’un PDF Il existe plusieurs packages sous R permettant de manipuler les PDF. Pour en extraire le texte et les métadonnées, il y a le package pdftools. Néanmoins, pour pouvoir extraire plus particulièrement les données des tableaux, il existe le package tabulizer qui sert de lien à la bibliothèque java Tabula. C’est ce package que je vais utiliser pour pouvoir extraire les données d’un PDF. library(&quot;tabulizer&quot;) Pour montrer l’utilisation de ce package, je vais utiliser pour exemple un PDF téléchargé sur le site de la Réserve Naturelle Nationale (RNN) de la Haute Chaîne du Jura. Ce fichier contient des tableaux montrant les données de recensement pour le plan de gestion 2019-2020 de la faune présente. # Chemin d&#39;accès au PDF pdf_data_jura &lt;- &quot;examples/faune-RNN-jura/Faune-vertebres-PG3.pdf&quot; Pour extraire les données, il faut utiliser la fonction extract_tables. Cette fonction renvoie par défaut une matrice ou une liste de matrices s’il y a plusieurs tableaux. On peut renvoyer directement un data.frame en ajoutant le paramètre output = \"data.frame\". Cependant, lors de la tentative de conversion, la structure du tableau peut ne pas correspondre au jeu de données réel. Je garde donc ici la sortie en matrice, puis je transforme ces matrices en data.frame. Vu qu’il y a plusieurs tableaux, la fonction extract_tables va sortir une liste de matrices. J’utilise donc la fonction map du package purrr pour appliquer la fonction as.data.frame de manière récursive sur tous les éléments de la liste. Ce package permet d’améliorer la partie programmation fonctionnelle dans R, notamment en remplaçant la plupart des boucles for. Le code devient ainsi plus succinct et plus facile à lire, tout en gardant son efficacité. jura_data &lt;- extract_tables(pdf_data_jura) %&gt;% purrr::map(as.data.frame) On peut ensuite vérifier que les tableaux correspondent à ce que l’on peut voir sur le PDF. Par exemple, on peut regarder les dimensions des tableaux à l’aide de la fonction dim. purrr::map(jura_data, dim) ## [[1]] ## [1] 21 15 ## ## [[2]] ## [1] 60 15 ## ## [[3]] ## [1] 71 16 ## ## [[4]] ## [1] 74 15 On peut déjà voir qu’il y a 4 tableaux au lieu de 3. C’est dû au fait que le 3ème tableau est séparé sur deux pages. De plus, les tableaux 1 et la première partie du 3 contiennent une colonne en trop (respectivement 15 au lieu de 14 et 16 au lieu de 15). Regardons alors de plus près ce que contiennent ces tableaux : # Récupération du nom des tableaux dans la liste. tableau &lt;- purrr::map(1:length(jura_data), ~ glue::glue(&quot;jura_data[[{.}]]&quot;)) # Récupération des dimensions des tableaux dimensions &lt;- purrr::map(jura_data, dim) %&gt;% purrr::map(~ glue::glue(&quot;{.[[1]]} lignes et {.[[2]]} colonnes&quot;)) %&gt;% unlist() # Création d&#39;un tableau interactif contenant l&#39;ensemble des jeux de données. all_output &lt;- my_reactable( data.frame(tableau = unlist(tableau), dimensions), details = function(index) { htmltools::div( my_reactable( jura_data[[index]], fullWidth = FALSE, pagination = FALSE, outlined = TRUE, compact = TRUE, height = 500, showPageSizeOptions = FALSE, showPageInfo = FALSE ) ) }, defaultPageSize = length(tableau), minRows = length(tableau), onClick = &quot;expand&quot;, rowStyle = list(cursor = &quot;pointer&quot;), rownames = FALSE, defaultColDef = colDef(na = &quot;&quot;) ) Tableau 2.1: Tableaux contenant les données brutes extraites du PDF (cliquer pour étendre les tableaux). Si on regarde les valeurs uniques des colonnes en trop pour jura_data[[1]] et jura_data[[3]], on s’aperçoit que la colonne du premier tableau est vide (\"\"), tandis que pour l’autre il y a la présence d’un \"1\". unique(jura_data[[1]][, 15]) ## [1] &quot;&quot; unique(jura_data[[3]][, 16]) ## [1] &quot;&quot; &quot;1&quot; On peut donc regarder la ligne où il y a l’erreur : line_id &lt;- which(jura_data[[3]][, 16] == &quot;1&quot;) my_reactable( jura_data[[3]][line_id,], height = &quot;auto&quot;, filterable = FALSE, defaultPageSize = 1, minRows = 1 ) La ligne qui en ressort est celle pour le Grand Tétras. En comparant avec la ligne du tableau sur le PDF, on peut se rendre compte qu’il y a un décalage à partir de la colonne de la Directive Oiseaux Annexe 1. Cela peut être dû à la mauvaise visualisation de la puce (bien présente) à la colonne “Protection nationale”. Cette puce ne semble pas visible, mais en surlignant avec la souris le texte de cette case, on peut voir apparaître la puce “•”. On peut donc réécrire correctement cette ligne d’après le PDF : # Modification de la ligne posant problème. jura_data[[3]][line_id,] &lt;- list( &quot;Tetrao urogallus major C. L. Brehm, 1831&quot;, &quot;Grand Tétras&quot;, &quot;2018&quot;, &quot;oui&quot;, &quot;oui&quot;, &quot;VU&quot;, &quot;CR&quot;, &quot;oui&quot;, NA, &quot;oui&quot;, NA, &quot;En déclin&quot;, &quot;Forte&quot;, &quot;Forte&quot;, &quot;1&quot;, &quot;&quot; ) Maintenant que cela est fait, on peut également observer qu’il faut nettoyer ces jeux de données. En effet, il faut d’abord mettre la première ligne en tant que nom des colonnes (fonction janitor::row_to_names). Ensuite il faut modifier les noms des colonnes pour les standardiser et être plus facilement utilisables dans les scripts (fonction janitor::clean_names). Il faut aussi rajouter des NA dans les cases vides (fonction dplyr::na_if). Les lignes et colonnes entièrement vides peuvent être supprimées (fonction janitor::remove_empty). Enfin, les puces typographiques “•” qui représentent la valeur booléenne TRUE doivent être remplacées par exemple par “oui”, pour que ces colonnes soient plus facilement manipulables (fonctions dplyr::mutate et dplyr::across). Pour ce faire, je crée une fonction pour que le code soit facilement réutilisable (et applicable dans la fonction purrr::map) : clean_extracted_data &lt;- function(data_extracted) { cleaned_df &lt;- data_extracted %&gt;% janitor::row_to_names(1) %&gt;% janitor::clean_names() # Création de la fonction qui remplacera les puces typographiques. replace_bullet &lt;- function(x) { if (is.na(x)) { output = x } else { if (x == &quot;•&quot;) { output = &quot;oui&quot; } else if (x == &quot;&quot;) { output = &quot;non&quot; } else { output = x } } return(output) } cleaned_df &lt;- cleaned_df %&gt;% # Pour chaque colonne ayant les puces, on les remplace. mutate(across(where(~ any(grepl(&quot;•&quot;, .))), ~ purrr::map_chr(., replace_bullet))) %&gt;% ungroup() %&gt;% # Pour les colonnes où les cases vides ne représentent pas des NA, on les # remplacent par &quot;—&quot;. mutate(across(starts_with(c(&quot;lr_&quot;, &quot;ec_&quot;)), ~ ifelse(. == &quot;&quot;, &quot;—&quot;, .))) %&gt;% na_if(&quot;&quot;) %&gt;% # On remplace les cases vides restantes par des NA. janitor::remove_empty(c(&quot;rows&quot;, &quot;cols&quot;)) # Suppression des lignes et colonnes vides rownames(cleaned_df) &lt;- NULL # Actualisation des numéros de ligne return(cleaned_df) } Ensuite, il ne reste plus qu’à appliquer cette fonction sur les tableaux extraits : jura_data_cleaned &lt;- jura_data %&gt;% purrr::map(clean_extracted_data) Les tableaux ressemblent maintenant à cela : Tableau 2.2: Tableaux contenant les données extraites du PDF et nettoyées (cliquer pour étendre les tableaux). On peut maintenant fusionner les deux sous-parties du tableau 3 (tableaux jura_data_cleaned[[3]] et jura_data_cleaned[[4]]) et visualiser les tableaux finaux : herpetofaune_jura &lt;- jura_data_cleaned[[1]] mammiferes_jura &lt;- jura_data_cleaned[[2]] avifaune_jura &lt;- bind_rows(jura_data_cleaned[[3]], jura_data_cleaned[[4]]) Tableau 2.3: Données présentant l’herpétofaune de la Réserve Naturelle Nationale de la Haute Chaîne du Jura. Tableau 2.4: Données présentant les mammifères de la Réserve Naturelle Nationale de la Haute Chaîne du Jura. Tableau 2.5: Données présentant l’avifaune de la Réserve Naturelle Nationale de la Haute Chaîne du Jura. 2.2 Récupération de données provenant du web : le web scraping Le web scraping est une technique permettant d’extraire, le plus souvent de façon automatique, le contenu d’une page web. Cela peut être très utile pour récupérer des données publiques nécessaires à nos analyses. Internet est un puits de connaissance, il faut donc en profiter et puiser ses ressources. Wikipédia peut être parfait pour cela. Sous R, le package permettant de parcourir et de récupérer facilement le contenu d’une page web s’appelle rvest. library(&quot;rvest&quot;) Ici, mon but est de récupérer la classification des différentes espèces d’oiseaux de la Réserve Naturelle Nationale de la Haute Chaîne du Jura (tableau 2.5). Cette classification peut être facilement récupérée sur les pages Wikipédia des oiseaux en question. Je veux donc créer une fonction qui va rechercher la page Wikipédia de l’oiseau voulu, puis récupérer sous la forme d’un tableau sa classification. get_bird_classification &lt;- function(bird, taxon = c(&quot;Ordre&quot;, &quot;Famille&quot;)) { wiki_link &lt;- &quot;https://fr.wikipedia.org/wiki/Wikip%C3%A9dia:Accueil_principal&quot; # On ouvre une session sur la page d&#39;accueil de Wikipédia session &lt;- html_session(wiki_link) # On écrit dans la barre de recherche le nom de l&#39;oiseau form &lt;- html_form(session) form_modified &lt;- set_values(form[[1]], search = bird) # On entre sur la page wikipédia de l&#39;oiseau wiki_bird &lt;- submit_form(session, form_modified, submit = &quot;go&quot;) tbl_classification &lt;- wiki_bird %&gt;% # On récupère le nœud HTML contenant le tableau html_node(xpath = &quot;//table[@class=&#39;taxobox_classification&#39;]&quot;) %&gt;% # On extrait le tableau html_table() %&gt;% # Puis on met en forme ce tableau magrittr::set_colnames(c(&quot;niveau_classification&quot;, &quot;nom_classification&quot;)) %&gt;% filter(niveau_classification %in% taxon) %&gt;% tidyr::pivot_wider( names_from = niveau_classification, values_from = nom_classification ) tbl_classification$nom &lt;- bird return(tbl_classification) } La fonction ainsi créée est utilisée sur les noms latin extraits du PDF. Pour enlever les noms de découvreur des espèces (exemple : « (Linnaeus, 1758) »), j’utilise une expression régulière qui identifie l’espèce et le genre des oiseaux (ça extrait les deux premiers mots de la chaîne de caractères). noms_latin &lt;- stringr::str_extract_all(avifaune_jura$nom_latin, r&quot;(^\\w+\\s+\\w+)&quot;) classification_oiseaux &lt;- purrr::map(noms_latin, get_bird_classification) %&gt;% bind_rows() # Fusion des tableaux Je fusionne ensuite le 1er tableau avec le tableau récupéré par web scraping. avifaune_jura &lt;- avifaune_jura %&gt;% mutate(nom = unlist(noms_latin)) %&gt;% left_join(classification_oiseaux, by = &quot;nom&quot;) %&gt;% select(-nom) %&gt;% relocate(Ordre:last_col()) Tableau 2.6: Données présentant l’avifaune de la Réserve Naturelle Nationale de la Haute Chaîne du Jura. Ces données ont été regroupées selon l’ordre et la famille des espèces présentes. (Cliquer pour étendre.) Télécharger au format CSV .sticky { position: sticky !important; background: hsl(233, 9%, 19%); z-index: 1; } .left-col-1 { left: 0; } .left-col-2 { left: 100px; } .left-col-3 { left: 200px; border-right: 1px solid hsl(233, 9%, 22%) !important; } Liste de ressources Internet utiles Courte comparaison entre les deux packages de text mining dans R. Introduction au tidy text mining. Introduction au package tabulizer. Tutoriel sur l’utilisation du package tabulizer. Autre tutoriel sur tabulizer. Catalogue des fonctions du package janitor pour l’exploration et le nettoyage des données. Introduction du package naniar pour la manipulation des valeurs manquantes. "],["statistique.html", "3 Statistique 3.1 Quelques notions clés 3.2 Statistique fréquentiste Liste de ressources Internet utiles 3.3 Statistique bayésienne Liste de ressources Internet utiles", " 3 Statistique Work In Progress 3.1 Quelques notions clés Concepts à comprendre : Théorie des probabilités Variable aléatoire réelle Fonction de répartition (ou fonction de distribution cumulative) d’une variable aléatoire Fonction de densité ou densité de probabilité 3.2 Statistique fréquentiste Liste de ressources Internet utiles 3.3 Statistique bayésienne Liste de ressources Internet utiles "],["dataviz.html", "4 Visualisation des données : la Dataviz", " 4 Visualisation des données : la Dataviz Work In Progress "],["SIG.html", "5 Systèmes d’Information Géographique &amp; Cartographie 5.1 Qu’est-ce qu’un SIG ? 5.2 R en tant que SIG 5.3 La représentation des données : les vecteurs et les rasters 5.4 Les Systèmes de Coordonnées de Référence Géographiques et Projetées 5.5 Les cartes interactives 5.6 Les cartes en 3D avec rayshader Liste de ressources Internet utiles", " 5 Systèmes d’Information Géographique &amp; Cartographie Work In Progress 5.1 Qu’est-ce qu’un SIG ? Un Système d’Information Géographique est, comme tout Système d’Information,1 un ensemble organisé de ressources ayant pour fonction de collecter, stocker, traiter et diffuser des informations.2 Ici, ces informations sont des données géospatiales stockées sous forme de couches d’informations superposées et reliées les unes aux autres par un référentiel cartographique.3 Les SIG sont devenus des outils essentiels dans de nombreux domaines tels que l’écologie, la météorologie, la médecine, ou la sociologie. Pour aider les utilisateurs au traitement des données géospatiales, il existe de performants et très utilisés logiciels gratuits ou payants tels que QGis ou ArcGIS. Ces logiciels offrent une approche graphique à la lecture, l’écriture, la manipulation et la visualisation des données. Ceci peut néanmoins limiter la reproductibilité et l’automatisation des projets. Pour remédier à cela, de nombreux langages de programmation peuvent être utilisés pour écrire et partager des scripts. Parmi les plus utilisés, il y a Python (qui est notamment utilisé pour la conception de plugins dans les logiciels de SIG) et R (dont les scripts sont maintenant exécutables dans QGis). En plus de cela, l’approche en lignes de commande permet de se libérer de certaines contraintes imposées par ces logiciels ainsi que d’avoir plus de contrôle sur ce que l’ont fait (même si ces logiciels sont de plus en plus performants). 5.2 R en tant que SIG Afin d’avoir un bon aperçu et une bonne base sur l’utilisation de R en tant que SIG, je vous invite à lire le livre Geocomputation with R de Lovelace, Nowosad, et Muenchow (2019). Ce livre est mis à jour régulièrement et consultable gratuitement à cette adresse : https://geocompr.robinlovelace.net/. Si vous préférez le format papier et/ou voulez soutenir les auteurs, il est bien sûr disponible à l’achat. Ayant commencé à apprendre les analyses statistiques avec R, c’est naturellement que je me suis tourné vers ce langage pour la cartographie et l’analyse des données géospatiales. En effet, la communauté de R a créé de performants et magnifiques packages de cartographie et de géocalcul libres, gratuits et bien documentés. Je m’intéresserai donc de plus près à ce qu’offre par exemple Python lorsque j’aurai maîtrisé suffisamment R. Un autre langage élégant et très récent qui est à regarder de très près est Julia, qui offrira certainement des packages rapides et performants au fur et à mesure de sa maturité. Par ailleurs, même si des programmes manqueraient à R ou si d’autres langages possèdent des programmes plus adaptés pour certaines tâches, des packages R offrent la possibilité d’en faciliter l’accès. Par exemple, les packages tels que Rcpp et Reticulate permettent l’utilisation de programmes écrits respectivement en C++ et Python. Outre cela, depuis peu j’ai eu le plaisir de voir un nouveau package émerger : qgisprocess. Ce package fournit une interface pour pouvoir utiliser les algorithmes disponibles dans QGIS. Il permet donc d’étendre les possibilités de R pour les SIG. D’autres caractéristiques intéressantes de R sont sa flexibilité et sa constante évolution. Par exemple, il offre maintenant la possibilité de faire facilement des applications web et des cartes interactives notamment via les packages Shiny et Leaflet. Il offre par la même occasion divers outils d’analyses avancées, de modélisation et de visualisation qui sont mis à jour et améliorés régulièrement. Pour plus d’informations concernant les atouts de R en tant que SIG ainsi qu’un bref aperçu de l’utilité des autres langages tels que Python, Java et C++, je vous invite à lire le chapitre Why use R for geocomputation du livre de Lovelace, Nowosad, et Muenchow (2019). 5.3 La représentation des données : les vecteurs et les rasters Pour représenter numériquement les données spatiales, deux modèles de base sont utilisés : les vecteurs (mode vectoriel) et les rasters (mode matriciel). L’une des principales différences entre ces deux modèles est qu’un vecteur est un objet (ou entité) tandis que le raster est une image. Ainsi, les vecteurs sont constitués de points, de lignes et de polygones créés à partir d’équations mathématiques, tandis que les rasters sont des grilles constituées de cellules de même taille (les pixels). C’est cette différence qui fait que les vecteurs ne perdent pas en netteté lorsque l’on zoome dessus, tandis que les images (rasters) deviennent floues (elles « pixelisent »). Par ailleurs, la différence dans la manière de stocker ces deux modèles fait que les fichiers liés aux vecteurs ont une taille bien inférieure que ceux liés aux raster. Sous R, les vecteurs et les rasters sont travaillés respectivement avec les packages sf et raster. 5.3.1 Les vecteurs Un vecteur est une image vectorielle ou dessin mathématique constitué de deux composantes : une composante attributaire permettant de l’identifier, et une composante graphique décrivant sa géométrie. Il est localisé grâce à un Système de Coordonnées de Référence (ou CRS pour Coordinate Reference System en anglais). Les vecteurs sont basiquement composés de nœuds ou sommets qui sont des points dans l’espace. À partir de ces sommets, des formules mathématiques sont appliquées pour créer des formes géométriques. S’il n’y a qu’un sommet, le vecteur est simplement un point. S’il y a plusieurs sommets et que les liaisons ne forment pas une forme géométrique fermée, alors cela forme une ligne. Si la forme est fermée, le vecteur est un polygone. La géométrie des points est généralement en deux dimensions (\\(x =\\) longitude, \\(y =\\) latitude), mais peut être parfois en trois dimensions si une valeur \\(z\\) additionnelle est ajoutée (notamment pour représenter la hauteur au-dessus du niveau de la mer). Les vecteurs permettent donc de représenter des données discrètes avec des formes bien définies dans l’espace. Pour stocker la géométrie de ces entités géographiques, l’OGC4 (Open Geospatial Consortium) a développé un modèle standardisé pour les Bases de Données Spatiales (BDS). Ce modèle s’appelle Modèle d’Entité Simple (SFA pour Simple Feature Access en anglais) et permet de définir des fonctions pour accéder, faire des calculs et construire les données, dans le but de représenter les objets dans la réalité. C’est un modèle de données très largement supporté dans la plupart des logiciels SIG (dont QGIS) et a l’avantage de rendre le travail totalement transférable d’un projet à un autre grâce à une architecture commune. Pour amener ce modèle dans R, le package sf a ainsi été créé pour succéder au package sp sur le long terme.5 Les différents types de géométrie définis par la norme standardisée de l’OGC sont donc inclus dans ce package (fig. 5.1). Ces types de géométrie permettent de créer les entités, qui sont la représentation d’un objet dans le monde réel (comme un bâtiment, un champ ou un arbre). Chaque entité peut alors faire partie par exemple du type POINT, POLYLIGNE (LINESTRING) ou POLYGONE. En plus de cela, il est possible de créer d’autres entités à partir de l’agrégation de ces entités basiques (formant des MULITPOINTS, des MULTIPOLYLIGNES et des MULTIPOLYGONES). Une seule entité contenant plusieurs types de géométrie différents est alors de type « collection de géométrie » (GEOMETRYCOLLECTION). Ces 7 types de géométrie précédemment cités font partis des types les plus utilisés. Ils peuvent être facilement créés avec le package sf. Il faut alors savoir que : library(&quot;sf&quot;) Un POINT est un vecteur : POINT &lt;- c(-0.25, 1) st_point(POINT) ## POINT (-0.25 1) Un MULTIPOINT est une matrice : MULTIPOINT &lt;- rbind(c(-0.25, 1), c(0.25, 1)) st_multipoint(MULTIPOINT) ## MULTIPOINT ((-0.25 1), (0.25 1)) Un LINESTRING est une matrice : LINESTRING &lt;- rbind(c(-1, 1), c(-1, 2.5), c(0, 1.5)) st_linestring(LINESTRING) ## LINESTRING (-1 1, -1 2.5, 0 1.5) On peut alors créer un contour avec un LINESTRING qui se ferme : LINESTRING_boundary &lt;- rbind(c(-1, 1), c(-1, 2.5), c(0, 1.5), c(-1, 1)) st_linestring(LINESTRING_boundary) ## LINESTRING (-1 1, -1 2.5, 0 1.5, -1 1) Un MULTILINESTRING est une liste de matrices : MULTILINESTRING &lt;- list( LINESTRING, rbind(c(1, 1), c(1, 2.5)) ) st_multilinestring(MULTILINESTRING) ## MULTILINESTRING ((-1 1, -1 2.5, 0 1.5), (1 1, 1 2.5)) Un POLYGON est une liste de matrices : POLYGON &lt;- list( rbind(c(0, 0), c(-1, 1), c(0, 1.5), c(1, 1), c(0, 0)) ) st_polygon(POLYGON) ## POLYGON ((0 0, -1 1, 0 1.5, 1 1, 0 0)) Un MULTIPOLYGON est une liste de listes de matrices : MULTIPOLYGONE &lt;- list( POLYGON, list(rbind(c(-1, 1), c(-1, 2.5), c(0, 1.5), c(-1, 1))), list(rbind(c(1, 1), c(1, 2.5), c(0, 1.5), c(1, 1))) ) st_multipolygon(MULTIPOLYGONE) ## MULTIPOLYGON (((0 0, -1 1, 0 1.5, 1 1, 0 0)), ((-1 1, -1 2.5, 0 1.5, -1 1)), ((1 1, 1 2.5, 0 1.5, 1 1))) Un GEOMETRYCOLLECTION est une liste de tous les autres types de géométrie : GEOMETRYCOLLECTION &lt;- list( st_multipolygon(MULTIPOLYGONE), st_multipoint(MULTIPOINT) ) st_geometrycollection(GEOMETRYCOLLECTION) ## GEOMETRYCOLLECTION (MULTIPOLYGON (((0 0, -1 1, 0 1.5, 1 1, 0 0)), ((-1 1, -1 2.5, 0 1.5, -1 1)), ((1 1, 1 2.5, 0 1.5, 1 1))), MULTIPOINT ((-0.25 1), (0.25 1))) Figure 5.1: Principaux types de géométries pour le Modèle d’Entité Simple (SFA). Le package sf est multitâche, il permet de : lire et écrire des fichiers de données spatiales via la bibliothèque GEOS ; faire des opérations géométriques via la bibliothèque GDAL ; mais aussi représenter et transformer des systèmes de coordonnées projetées, à partir de la bibliothèque PROJ. 5.3.1.1 Lecture des fichiers de données spatiales pour les vecteurs Pour avoir un aperçu des objets sf sous R, nous allons prendre pour exemple les données de localisation des Réserves Naturelles Nationales (RNN) de la France métropolitaine (Tableau 5.1). Ces données proviennent de l’Inventaire National du Patrimoine Naturel (INPN) et elles sont trouvables sur le site du gouvernement. Plusieurs formats de fichier peuvent être utilisés pour stocker les données des vecteurs. Les plus utilisés sont le format Shapefile (.shp) de la société ESRI, les formats Keyhole Markup Language (.kml) de Google (et qui peut être compressé sous le format .kmz), ou aussi le format Geographic Markup Language (.gml) développé par l’OGC. Concernant les données spatiales des RNN, elles sont téléchargeables au format Shapefile. Il faut alors savoir que le format Shapefile est toujours accompagné d’autres fichiers, dont les plus importants sont le fichier .dbf contenant les données attributaires, ainsi que le fichier .shx contenant l’index de la géométrie. Le fichier .shp contient, lui, les caractéristiques géométriques des différentes entités. C’est pour cela que lorsqu’on télécharge des données au format Shapefile, on télécharge en réalité tout un dossier contenant plusieurs fichiers. Une fois le package sf chargé, pour lire les données spatiales il faut utiliser la fonction st_read(). Pour cet exemple, il suffit alors de lui donner le chemin d’accès au fichier .shp. Les autres fichiers qui lui sont liés doivent être stockés au même endroit. Pour plus d’informations sur les différents paramètres et les différentes possibilités de cette fonction, il ne faut pas hésiter à aller lire sa documentation. # Lecture de la base de données data_rnn &lt;- st_read(&quot;examples/rnn2019_12/N_ENP_RNN_S_000.shp&quot;) ## Reading layer `N_ENP_RNN_S_000&#39; from data source `/home/alexis/Documents/doc Alexis Merot/Mon_aide_memoire/examples/rnn2019_12/N_ENP_RNN_S_000.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 151 features and 30 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: 107791.7 ymin: 6145089 xmax: 1077646 ymax: 7109090 ## projected CRS: RGF93 / Lambert-93 Des informations importantes sont alors affichées après lecture du fichier. On peut y lire dans l’ordre : la couche spatiale utilisée ainsi que le chemin d’accès du fichier source ; le type de l’objet ainsi créé et sa courte description ; le type de géométrie des différentes entités ; les dimensions spatiales ; les coordonnées délimitant la zone géographique (bounding box) ; et enfin le Système de Coordonnées de Référence. En regardant l’objet sf alors créé, on peut s’apercevoir qu’il a la forme d’un tableau de données comme on a l’habitude de voir. Cette caractéristique permet de le manipuler facilement, notamment via le package dplyr. En réalité, cet objet est bien de classe data.frame, mais il possède en plus la classe sf du fait de sa dernière colonne : geometry. Cette colonne est une liste contenant la géométrie des différentes entités de la couche. La liste entière est de classe sfc (simple feature list-column) et chaque élément de cette liste est de classe sfg (simple feature geometry). Cette structure de données possède donc bien la composante graphique des vecteurs (colonne geometry) ainsi que leur composante attributaire (toutes les autres colonnes). Tableau 5.1: Jeu de données spatiales montrant les Réserves Naturelles Nationales de la France métropolitaine. On peut visualiser les attributs de l’objet data_rnn à l’aide de la fonction attributes : attributes(data_rnn) ## $names ## [1] &quot;ID_LOCAL&quot; &quot;PRN_ASSO&quot; &quot;CODE_R_ENP&quot; &quot;NOM_SITE&quot; ## [5] &quot;DATE_CREA&quot; &quot;MODIF_ADM&quot; &quot;MODIF_GEO&quot; &quot;URL_FICHE&quot; ## [9] &quot;SURF_OFF&quot; &quot;ACTE_DEB&quot; &quot;ACTE_FIN&quot; &quot;GEST_SITE&quot; ## [13] &quot;OPERATEUR&quot; &quot;SRC_GEOM&quot; &quot;SRC_ANNEE&quot; &quot;MARIN&quot; ## [17] &quot;P1_NATURE&quot; &quot;P2_CULTURE&quot; &quot;P3_PAYSAGE&quot; &quot;P4_GEOLOGI&quot; ## [21] &quot;P5_SPELEO&quot; &quot;P6_ARCHEO&quot; &quot;P7_PALEOB&quot; &quot;P8_ANTHROP&quot; ## [25] &quot;P9_SCIENCE&quot; &quot;P10_PUBLIC&quot; &quot;P11_DD&quot; &quot;P12_AUTRE&quot; ## [29] &quot;ID_MNHN&quot; &quot;PRECISION&quot; &quot;geometry&quot; ## ## $row.names ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 ## [14] 14 15 16 17 18 19 20 21 22 23 24 25 26 ## [27] 27 28 29 30 31 32 33 34 35 36 37 38 39 ## [40] 40 41 42 43 44 45 46 47 48 49 50 51 52 ## [53] 53 54 55 56 57 58 59 60 61 62 63 64 65 ## [66] 66 67 68 69 70 71 72 73 74 75 76 77 78 ## [79] 79 80 81 82 83 84 85 86 87 88 89 90 91 ## [92] 92 93 94 95 96 97 98 99 100 101 102 103 104 ## [105] 105 106 107 108 109 110 111 112 113 114 115 116 117 ## [118] 118 119 120 121 122 123 124 125 126 127 128 129 130 ## [131] 131 132 133 134 135 136 137 138 139 140 141 142 143 ## [144] 144 145 146 147 148 149 150 151 ## ## $class ## [1] &quot;sf&quot; &quot;data.frame&quot; ## ## $sf_column ## [1] &quot;geometry&quot; ## ## $agr ## ID_LOCAL PRN_ASSO CODE_R_ENP NOM_SITE DATE_CREA ## &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## MODIF_ADM MODIF_GEO URL_FICHE SURF_OFF ACTE_DEB ## &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## ACTE_FIN GEST_SITE OPERATEUR SRC_GEOM SRC_ANNEE ## &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## MARIN P1_NATURE P2_CULTURE P3_PAYSAGE P4_GEOLOGI ## &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## P5_SPELEO P6_ARCHEO P7_PALEOB P8_ANTHROP P9_SCIENCE ## &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## P10_PUBLIC P11_DD P12_AUTRE ID_MNHN PRECISION ## &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## Levels: constant aggregate identity De même pour la colonne geometry : attributes(data_rnn$geometry) ## $n_empty ## [1] 0 ## ## $crs ## Coordinate Reference System: ## User input: RGF93 / Lambert-93 ## wkt: ## PROJCRS[&quot;RGF93 / Lambert-93&quot;, ## BASEGEOGCRS[&quot;RGF93&quot;, ## DATUM[&quot;Reseau Geodesique Francais 1993&quot;, ## ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101, ## LENGTHUNIT[&quot;metre&quot;,1]]], ## PRIMEM[&quot;Greenwich&quot;,0, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## ID[&quot;EPSG&quot;,4171]], ## CONVERSION[&quot;Lambert-93&quot;, ## METHOD[&quot;Lambert Conic Conformal (2SP)&quot;, ## ID[&quot;EPSG&quot;,9802]], ## PARAMETER[&quot;Latitude of false origin&quot;,46.5, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8821]], ## PARAMETER[&quot;Longitude of false origin&quot;,3, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8822]], ## PARAMETER[&quot;Latitude of 1st standard parallel&quot;,49, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8823]], ## PARAMETER[&quot;Latitude of 2nd standard parallel&quot;,44, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8824]], ## PARAMETER[&quot;Easting at false origin&quot;,700000, ## LENGTHUNIT[&quot;metre&quot;,1], ## ID[&quot;EPSG&quot;,8826]], ## PARAMETER[&quot;Northing at false origin&quot;,6600000, ## LENGTHUNIT[&quot;metre&quot;,1], ## ID[&quot;EPSG&quot;,8827]]], ## CS[Cartesian,2], ## AXIS[&quot;easting (X)&quot;,east, ## ORDER[1], ## LENGTHUNIT[&quot;metre&quot;,1]], ## AXIS[&quot;northing (Y)&quot;,north, ## ORDER[2], ## LENGTHUNIT[&quot;metre&quot;,1]], ## USAGE[ ## SCOPE[&quot;unknown&quot;], ## AREA[&quot;France&quot;], ## BBOX[41.15,-9.86,51.56,10.38]], ## ID[&quot;EPSG&quot;,2154]] ## ## $class ## [1] &quot;sfc_MULTIPOLYGON&quot; &quot;sfc&quot; ## ## $precision ## [1] 0 ## ## $bbox ## xmin ymin xmax ymax ## 107791.7 6145088.5 1077645.6 7109090.0 Parfois, il peut être utile de récupérer le Système de Coordonnées de Référence dans un autre format : le format proj4string. Cette notation provient de la librairie PROJ (anciennement PROJ.4). Elle permet de définir le Système de Coordonnées directement à l’intérieur d’une chaîne de caractères. Pour l’instant, le nom proj4string est resté dans R, mais dans la documentation officielle le nom de cette notation est maintenant proj-string. Par exemple, ici le proj4string vaut : st_crs(data_rnn)$proj4string ## [1] &quot;+proj=lcc +lat_0=46.5 +lon_0=3 +lat_1=49 +lat_2=44 +x_0=700000 +y_0=6600000 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs&quot; 5.3.1.2 Création de cartes à partir de vecteurs library(&quot;ggspatial&quot;) # Extension de ggplot2 pour la cartographie # Ajout des départements français. regions &lt;- st_read(&quot;examples/regions-20180101-shp/regions-20180101.shp&quot;) %&gt;% filter(code_insee %in% 1:95) ## Reading layer `regions-20180101&#39; from data source `/home/alexis/Documents/doc Alexis Merot/Mon_aide_memoire/examples/regions-20180101-shp/regions-20180101.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 18 features and 5 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: -61.80976 ymin: -21.38973 xmax: 55.83669 ymax: 51.08899 ## geographic CRS: WGS 84 # Les données ne sont pas dans le bon référentiel (WGS 84). # La projection Lambert 93 du référentiel RGF93 a pour référence EPSG:2154. # regions &lt;- st_transform(regions, 2154) data_rnn &lt;- st_transform(data_rnn, 4326) # Ajout des coordonnées dans le tableau pour faciliter la création des labels # Vu que ce sont des polygones, on calcule leur centre pour avoir un point. data_rnn &lt;- cbind(data_rnn, st_coordinates(st_point_on_surface(data_rnn))) # Localisation des réserves en France métropolitaine rnn_france &lt;- ggplot(regions) + annotation_map_tile( zoom = 5, zoomin = 0, type = &quot;stamenwatercolor&quot;, progress = &quot;none&quot; ) + geom_sf( aes(fill = nom), colour = &quot;black&quot;, alpha = 0.6, show.legend = FALSE ) + # Lien entre cartes non-zoomée et zoomée geom_diagonal( aes(x = 14, xend = 12.5, y = 46, yend = 47.2) ) + geom_label_repel( seed = 42, data = filter(data_rnn, ID_LOCAL == &quot;RNN112&quot;), aes(x = X, y = Y, label = &quot;Haute Chaîne\\ndu Jura&quot;), size = 4, nudge_x = 6, nudge_y = 1.2, segment.curvature = 0.5, segment.ncp = 1, segment.angle = 10, ) + geom_point( data = data_rnn, aes(x = X, y = Y), colour = &quot;darkred&quot;, size = 2 ) + annotation_north_arrow( location = &quot;bl&quot;, which_north = &quot;true&quot;, style = north_arrow_nautical() ) + coord_sf(datum = st_crs(4326)) + theme_linedraw() + theme( panel.ontop = TRUE, panel.background = element_blank(), axis.title = element_blank() ) # On récupère les limites inférieures et supérieures de la RNN de la haute # chaîne du Jura. crop_limits &lt;- st_bbox(filter(data_rnn, ID_LOCAL == &quot;RNN112&quot;)) # On zoome sur la carte des régions en augmentant les limites précédentes # par 10 km. crop_regions &lt;- st_crop(regions, crop_limits + c(-0.1, -0.1, 0.15, 0.1)) rnn_jura &lt;- ggplot(crop_regions) + annotation_map_tile(zoomin = -1, type = &quot;stamenwatercolor&quot;, progress = &quot;none&quot;) + geom_sf(data = crop_regions, colour = &quot;black&quot;, fill = NA, size = 1.05) + geom_sf(data = filter(data_rnn, ID_LOCAL == &quot;RNN112&quot;), fill = &quot;darkred&quot;) + coord_sf(expand = FALSE, datum = st_crs(4326)) + theme_map() + theme( panel.border = element_rect(colour = &quot;black&quot;, fill = NA, size = 2), panel.ontop = TRUE ) layout_design &lt;- c( area(t = 1, l = 1, b = 8, r = 7), area(t = 5, l = 6, b = 8, r = 8) ) rnn_france + rnn_jura + plot_layout(design = layout_design) + plot_annotation(caption = &quot;\\u00a9 OpenStreetMap contributors&quot;) Figure 5.2: Carte montrant la localisation géographique (point rouge) des Réserves Naturelles Nationales de la France métropolitaine. Un zoom a été fait pour apercevoir la délimitation de la Réserve Nationale de la Haute Chaîne du Jura. 5.3.2 Les rasters Un raster représente une image constituée de pixels (cellules) organisé(e)s sous la forme d’une grille. C’est la représentation que l’on a l’habitude de voir lorsque l’on parle d’une image numérique. Chaque pixel est unique et possède certaines valeurs le caractérisant (comme sa couleur, ses coordonnées, son altitude…). Les données sont ainsi organisées en matrice, où chaque cellule correspond à un pixel. Pour bien superposer le raster à la carte, les matrices possèdent une en-tête incluant le Système de Coordonnées de Référence, l’origine (généralement les coordonnées du coin inférieur droit de la matrice), ainsi que l’étendue de la matrice (le nombre de colonnes, de lignes et la résolution spatiale6). De par leurs caractéristiques, les rasters permettent de définir des données discrètes ainsi que des données continues. 5.4 Les Systèmes de Coordonnées de Référence Géographiques et Projetées 5.5 Les cartes interactives 5.5.1 Le package ggiraph library(&quot;ggiraph&quot;) # Communes du pays de Gex pays_de_gex &lt;- st_read(&quot;examples/communes-pays-de-gex/communes-pays-de-gex.shp&quot;) ## Reading layer `communes-pays-de-gex&#39; from data source `/home/alexis/Documents/doc Alexis Merot/Mon_aide_memoire/examples/communes-pays-de-gex/communes-pays-de-gex.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 27 features and 4 fields ## geometry type: POLYGON ## dimension: XY ## bbox: xmin: 5.81358 ymin: 46.08513 xmax: 6.170027 ymax: 46.41781 ## geographic CRS: WGS 84 rnn_jura_interactive &lt;- ggplot(crop_regions) + annotation_map_tile(zoomin = -1, type = &quot;stamenwatercolor&quot;, progress = &quot;none&quot;) + geom_sf(data = crop_regions, colour = &quot;black&quot;, fill = NA, size = 1.1) + geom_sf( data = filter(data_rnn, ID_LOCAL == &quot;RNN112&quot;), fill = &quot;darkred&quot;, colour = &quot;darkred&quot; ) + geom_sf_interactive( data = pays_de_gex, aes(tooltip = nom, data_id = insee), colour = &quot;black&quot;, fill = &quot;black&quot;, alpha = 0.3 ) + labs(caption = &quot;© OpenStreetMap contributors&quot;) + coord_sf(expand = FALSE, datum = st_crs(4326)) + theme_map() + theme_linedraw() + theme( panel.ontop = TRUE, panel.background = element_blank(), axis.title = element_blank() ) girafe( code = print(rnn_jura_interactive), options = list( opts_hover(css = &quot;fill:orange;&quot;), opts_hover_inv(css = &quot;opacity:0.2;&quot;), opts_zoom(max = 5) ) ) Figure 5.3: Carte de la délimitation (en rouge) de la Réserve Naturelle Nationale de la Haute-Chaîne du Jura. Le nom des communes de la Communauté d’Agglomération du Pays de Gex est visible interactivement en passant dessus le curseur de la souris. 5.5.2 Le package mapview library(&quot;mapview&quot;) Pour afficher toutes les options globales disponibles dans mapview : mapviewOptions() ## ## global options: ## ## platform : leaflet ## basemaps : CartoDB.Positron CartoDB.DarkMatter OpenStreetMap Esri.WorldImagery OpenTopoMap ## raster.palette : function (n) ## vector.palette : function (n) ## verbose : FALSE ## na.color : #BEBEBE80 ## legend : TRUE ## legend.opacity : 1 ## legend.pos : topright ## layers.control.pos : topleft ## leafletWidth : ## leafletHeight : ## viewer.suppress : FALSE ## homebutton : TRUE ## homebutton.pos : bottomright ## native.crs : FALSE ## watch : FALSE ## fgb : TRUE ## ## raster data related options: ## ## raster.size : 8388608 ## mapview.maxpixels : 5e+05 ## plainview.maxpixels : 1e+07 ## use.layer.names : FALSE ## trim : TRUE ## method : bilinear ## query.type : mousemove ## query.digits : 7 ## query.position : topright ## query.prefix : Layer ## ## vector data realted options: ## ## maxpolygons : 30000 ## maxpoints : 20000 ## maxlines : 30000 ## pane : auto ## cex : 6 ## alpha : 0.9 map_types &lt;- c( &quot;Esri.NatGeoWorldMap&quot;, &quot;OpenTopoMap&quot;, &quot;GeoportailFrance.maps&quot;, &quot;GeoportailFrance.orthos&quot;, &quot;OpenStreetMap.France&quot; ) description_rnn &lt;- data_rnn %&gt;% st_drop_geometry() %&gt;% select(NOM_SITE, DATE_CREA, OPERATEUR, SURF_OFF, ID_MNHN, URL_FICHE) %&gt;% mutate( description = glue( &#39; &lt;h1 style=&quot;border: 3px solid; text-align: center; border-radius: 15px&quot;&gt; {NOM_SITE} &lt;/h1&gt; &lt;b&gt;Date de création&lt;/b&gt; : {format(DATE_CREA, &quot;%d/%m/%Y&quot;)}&lt;br&gt; &lt;b&gt;Opérateur&lt;/b&gt; : {OPERATEUR}&lt;br&gt; &lt;b&gt;Superficie officielle&lt;/b&gt; : {SURF_OFF} ha&lt;br&gt; &lt;b&gt;Identifiant du MNHN&lt;/b&gt; : {ID_MNHN}&lt;br&gt; &lt;b&gt;Lien&lt;/b&gt; : &lt;a href={URL_FICHE}&gt;{URL_FICHE}&lt;/a&gt;&lt;br&gt; &#39; ) ) %&gt;% pull(description) st_point_on_surface(data_rnn) %&gt;% mapview( col.regions = &quot;darkred&quot;, layer.name = &quot;Réserves Naturelles Nationales&quot;, map.types = map_types, label = &quot;NOM_SITE&quot;, popup = description_rnn, cex = &quot;SURF_OFF&quot; ) Figure 5.4: Carte interactive montrant la localisation des Réserves Naturelles Nationales en France métropolitaine. La taille des points est proportionnelle à la superficie des réserves. Une courte description est visible en cliquant sur les points. 5.6 Les cartes en 3D avec rayshader library(&quot;rayshader&quot;) library(&quot;raster&quot;) # Zone géographique d&#39;intérêt. boundary_box &lt;- extent( 843442, 866595, 6686564, 6703526 ) # Chargement de la carte historique de Dijon. cassini &lt;- stack(&quot;examples/3d_map/dijon/Carte_générale_de_la_France_Dalier_(17_btv1b53095148b_1_georef.tif&quot;) # Recadrage sur la zone d&#39;intérêt. cassini_croped &lt;- crop(cassini, boundary_box) # Visualisation du raster RGB. plotRGB(cassini_croped) Figure 5.5: Carte 2D en couleur de Cassini (XVIIIe siècle) montrant la ville de Dijon en France. # Transformation en array cassini_array &lt;- as.array(cassini_croped) # Chargement de la carte d&#39;élévation. dijon_topo &lt;- raster(&quot;examples/3d_map/dijon/BDALTIV2_75M_FXX_0825_6750_MNT_LAMB93_IGN69.asc&quot;) crs(dijon_topo) &lt;- CRS(&quot;+init=EPSG:2154&quot;) dijon_topo &lt;- crop(dijon_topo, boundary_box) %&gt;% raster_to_matrix() # Création des couches pour les ombres ray_layer &lt;- ray_shade(dijon_topo, zscale = 20, multicore = TRUE) ambient_layer &lt;- ambient_shade( dijon_topo, zscale = 10, multicore = TRUE, maxsearch = 200 ) # On divise par 255 pour avoir des valeurs entre 0 et 1. # (L&#39;étendue des couleurs RGB est en effet entre 0 et 255.) # Carte en 3D en vue de dessus, avec la fonction `plot_map` (cassini_array/255) %&gt;% add_shadow(ray_layer, 0.3) %&gt;% add_shadow(ambient_layer, 0) %&gt;% plot_map() Figure 5.6: Carte de Cassini (XVIIIe siècle) en 3D et en vue de dessus, montrant la ville de Dijon en France. # Carte en 3D avec la fonction `plot_3d` permettant de changer la position de la caméra. (cassini_array/255) %&gt;% add_shadow(ray_layer, 0.3) %&gt;% add_shadow(ambient_layer, 0) %&gt;% plot_3d(dijon_topo, zscale = 30) # On crée une vue de dessus. # Je mets ici -90 car la fonction `render_highquality` va inverser cette valeur, # je ne sais pas si c&#39;est un bug (-90 deviendra la bonne valeur : 90). render_camera( zoom = 0.5, phi = -90, # Angle d&#39;azimut (max 90) theta = 0 # Angle de rotation ) render_highquality( lightaltitude = 25, environment_light = &quot;examples/3d_map/HDRI/kiara_1_dawn_4k.hdr&quot; ) Figure 5.7: Carte de Cassini (XVIIIe siècle) en 3D et en vue de dessus, montrant la ville de Dijon en France. Le rendu de la lumière est ici de meilleure qualité. # zscale plus élevé (cassini_array/255) %&gt;% add_shadow(ray_layer, 0.3) %&gt;% add_shadow(ambient_layer, 0) %&gt;% plot_3d(dijon_topo, zscale = 60) # On positionne la caméra sur le côté. render_camera( zoom = 0.3, phi = 15, # Angle d&#39;azimut (max 90) theta = 55 # Angle de rotation ) # Meilleure qualité render_highquality( light = TRUE, lightaltitude = 25, environment_light = &quot;examples/3d_map/HDRI/kiara_1_dawn_4k.hdr&quot; ) Figure 5.8: Carte de Cassini (XVIIIe siècle) en 3D montrant la ville de Dijon en France. La caméra a été déplacée pour avoir une vue sur le côté. # On rajoute de la profondeur de champs (bokeh) render_depth( focus = 0.52, environment_light = &quot;examples/3d_map/HDRI/kiara_1_dawn_4k.hdr&quot; ) Figure 5.9: Carte de Cassini (XVIIIe siècle) en 3D montrant la ville de Dijon en France. La profondeur de champ a été ajoutée pour créer un effet bokeh. # Caméra pour la vidéo render_camera( zoom = 0.3, phi = 25, # Angle d&#39;azimut (max 90) theta = 0 # Angle de rotation ) render_movie( &quot;images/3d_map_export/dijon_3d_audio&quot;, type = &quot;oscillate&quot;, frames = 720, audio = &quot;examples/3d_map/musique/jacques-gallot-suite-in-f-sharp-minor-prelude-a-magical-music.mp3&quot; ) Vidéo de la carte de Cassini (XVIIIe siècle) en 3D montrant la ville de Dijon en France. (Audio : Prélude de la suite en Fa dièse majeur, Jacques de Gallot.) Sorry, your browser doesn’t support embedded videos. Liste de ressources Internet utiles Guide sur les analyses de données géographiques, leur visualisation et leur modélisation sur R Introduction à l’utilisation des packages de cartographie sur R Introduction au package sf Édition interactive de cartes avec mapedit introduction à l’utilisation de R comme un SIG Introduction pour créer des cartes avec R Introduction en français pour créer des cartes avec R Introduction en français sur le package rgeoapi Zoomer sur une carte avec R Tracer des cartes avec ggplot2 via des fichiers shapefiles Tutoriel pour dessiner des cartes avec R, sf et ggplot2 Cartes interactives avec mapview Cartes interactives avec leaflet Guide pour faire des cartes en 3D à partir d’une imagerie satellite Utilisation du package rayshader pour la création de cartes en 2D et 3D Manipulation et visualisation de données LiDAR pour la foresterie avec lidr Blog français contenant divers tutoriels sur la SIG et QGis NaturaGIS : tutoriels et ressources sur la géomatique, les SIG et leurs usages pour l’environnement Documentation officielle de QGIS Références "],["session-info.html", "Session info", " Session info ## ─ Session info ─────────────────────────────────────────── ## setting value ## version R version 4.0.3 (2020-10-10) ## os Ubuntu 20.04.1 LTS ## system x86_64, linux-gnu ## ui X11 ## language (EN) ## collate fr_FR.UTF-8 ## ctype fr_FR.UTF-8 ## tz Europe/Paris ## date 2020-11-17 ## ## ─ Packages ─────────────────────────────────────────────── ## package * version date lib ## abind 1.4-5 2016-07-21 [1] ## assertthat 0.2.1 2019-03-21 [3] ## base64enc 0.1-3 2015-07-28 [3] ## bookdown 0.21 2020-10-13 [1] ## bsplus 0.1.2 2020-06-25 [1] ## class 7.3-17 2020-04-26 [4] ## classInt 0.4-3 2020-04-07 [1] ## cli 2.1.0 2020-10-12 [1] ## codetools 0.2-18 2020-11-04 [4] ## colorspace 2.0-0 2020-11-11 [1] ## crayon 1.3.4 2017-09-16 [3] ## crosstalk 1.1.0.1 2020-03-13 [3] ## DBI 1.1.0 2019-12-15 [1] ## DiagrammeR 1.0.6.9000 2020-09-10 [1] ## digest 0.6.27 2020-10-24 [3] ## downloadthis 0.2.1 2020-09-17 [1] ## dplyr * 1.0.2 2020-08-18 [1] ## e1071 1.7-4 2020-10-14 [1] ## ellipsis 0.3.1 2020-05-15 [3] ## evaluate 0.14 2019-05-28 [3] ## fansi 0.4.1 2020-01-08 [3] ## farver 2.0.3 2020-01-16 [3] ## fs 1.5.0 2020-07-31 [3] ## gdtools 0.2.2 2020-04-03 [3] ## generics 0.1.0 2020-10-31 [1] ## ggforce * 0.3.2 2020-06-23 [1] ## ggiraph * 0.7.9 2020-09-03 [1] ## ggplot2 * 3.3.2.9000 2020-11-17 [1] ## ggrepel * 0.9.0 2020-08-11 [1] ## ggspatial * 1.1.4 2020-07-12 [1] ## ggthemes * 4.2.0 2019-05-13 [1] ## glue * 1.4.2 2020-08-27 [1] ## gtable 0.3.0 2019-03-25 [3] ## highr 0.8 2019-03-20 [3] ## hms 0.5.3 2020-01-08 [1] ## htmltools 0.5.0 2020-06-16 [3] ## htmlwidgets 1.5.2 2020-10-03 [3] ## httr 1.4.2 2020-07-20 [3] ## janitor 2.0.1 2020-04-12 [1] ## jpeg 0.1-8.1 2019-10-24 [1] ## jsonlite 1.7.1 2020-09-07 [1] ## KernSmooth 2.23-18 2020-10-29 [4] ## knitr 1.30 2020-09-22 [1] ## lattice 0.20-41 2020-04-02 [4] ## leafem 0.1.3 2020-07-26 [1] ## leaflet 2.0.3 2019-11-16 [1] ## lifecycle 0.2.0 2020-03-06 [3] ## lubridate 1.7.9.2 2020-11-13 [1] ## magrittr 1.5 2014-11-22 [3] ## mapview * 2.9.0 2020-08-11 [1] ## MASS 7.3-53 2020-09-09 [4] ## mime 0.9 2020-02-04 [3] ## munsell 0.5.0 2018-06-12 [3] ## patchwork * 1.1.0 2020-11-09 [1] ## pillar 1.4.6 2020-07-10 [3] ## pkgconfig 2.0.3 2019-09-22 [3] ## plyr 1.8.6 2020-03-03 [1] ## png 0.1-7 2013-12-03 [3] ## polyclip 1.10-0 2019-03-14 [1] ## prettymapr 0.2.2 2017-09-20 [1] ## purrr 0.3.4 2020-04-17 [3] ## R6 2.5.0 2020-10-28 [3] ## raster 3.4-5 2020-11-14 [1] ## RColorBrewer 1.1-2 2014-12-07 [3] ## Rcpp 1.0.5 2020-07-06 [3] ## reactable * 0.2.3 2020-10-04 [1] ## reactR 0.4.3 2020-07-12 [1] ## readr 1.4.0 2020-10-05 [1] ## rgdal 1.5-18 2020-10-13 [1] ## rJava 0.9-13 2020-07-06 [3] ## rlang 0.4.8 2020-10-08 [1] ## rmarkdown 2.5 2020-10-21 [1] ## rosm 0.2.5 2019-07-22 [1] ## rstudioapi 0.13 2020-11-12 [1] ## rvest * 0.3.6 2020-07-25 [1] ## satellite 1.0.2 2019-12-09 [1] ## scales 1.1.1 2020-05-11 [3] ## sessioninfo 1.1.1 2018-11-05 [3] ## sf * 0.9-6 2020-09-13 [1] ## snakecase 0.11.0 2019-05-25 [1] ## sp 1.4-4 2020-10-07 [1] ## stringi 1.5.3 2020-09-09 [1] ## stringr 1.4.0 2019-02-10 [3] ## systemfonts 0.3.2 2020-09-29 [1] ## tabulizer * 0.2.2 2020-08-15 [1] ## tabulizerjars 1.0.1 2020-08-15 [1] ## tibble 3.0.4 2020-10-12 [1] ## tidyselect 1.1.0 2020-05-11 [1] ## tweenr 1.0.1 2018-12-14 [1] ## units 0.6-7 2020-06-13 [1] ## uuid 0.1-4 2020-02-26 [1] ## vctrs 0.3.4 2020-08-29 [1] ## visNetwork 2.0.9 2019-12-06 [1] ## webshot 0.5.2 2019-11-22 [3] ## withr 2.3.0 2020-09-22 [1] ## xfun 0.19 2020-10-30 [1] ## xml2 * 1.3.2 2020-04-23 [3] ## yaml 2.2.1 2020-02-01 [3] ## source ## CRAN (R 4.0.1) ## CRAN (R 4.0.0) ## CRAN (R 4.0.0) ## CRAN (R 4.0.3) ## CRAN (R 4.0.3) ## CRAN (R 4.0.0) ## CRAN (R 4.0.1) ## CRAN (R 4.0.2) ## CRAN (R 4.0.3) ## CRAN (R 4.0.3) ## CRAN (R 4.0.0) ## CRAN (R 4.0.0) ## CRAN (R 4.0.1) ## Github (rich-iannone/DiagrammeR@b6a7019) ## CRAN (R 4.0.3) ## CRAN (R 4.0.3) ## CRAN (R 4.0.2) ## CRAN (R 4.0.3) ## CRAN (R 4.0.0) ## CRAN (R 4.0.0) ## CRAN (R 4.0.0) ## CRAN (R 4.0.0) ## CRAN (R 4.0.2) ## CRAN (R 4.0.0) ## CRAN (R 4.0.3) ## CRAN (R 4.0.1) ## Github (davidgohel/ggiraph@0abe7f1) ## Github (tidyverse/ggplot2@b76fa96) ## Github (slowkow/ggrepel@4d0ef50) ## CRAN (R 4.0.2) ## CRAN (R 4.0.1) ## CRAN (R 4.0.2) ## CRAN (R 4.0.0) ## CRAN (R 4.0.0) ## CRAN (R 4.0.1) ## CRAN (R 4.0.1) ## CRAN (R 4.0.2) ## CRAN (R 4.0.2) ## CRAN (R 4.0.1) ## CRAN (R 4.0.1) ## CRAN (R 4.0.2) ## CRAN (R 4.0.3) ## CRAN (R 4.0.2) ## CRAN (R 4.0.0) ## CRAN (R 4.0.2) ## CRAN (R 4.0.1) ## CRAN (R 4.0.0) ## CRAN (R 4.0.3) ## CRAN (R 4.0.0) ## CRAN (R 4.0.2) ## CRAN (R 4.0.2) ## CRAN (R 4.0.0) ## CRAN (R 4.0.0) ## CRAN (R 4.0.3) ## CRAN (R 4.0.2) ## CRAN (R 4.0.0) ## CRAN (R 4.0.1) ## CRAN (R 4.0.0) ## CRAN (R 4.0.1) ## CRAN (R 4.0.1) ## CRAN (R 4.0.0) ## CRAN (R 4.0.3) ## CRAN (R 4.0.3) ## CRAN (R 4.0.0) ## CRAN (R 4.0.2) ## CRAN (R 4.0.2) ## CRAN (R 4.0.2) ## CRAN (R 4.0.2) ## CRAN (R 4.0.3) ## CRAN (R 4.0.2) ## CRAN (R 4.0.2) ## CRAN (R 4.0.3) ## CRAN (R 4.0.2) ## CRAN (R 4.0.3) ## CRAN (R 4.0.2) ## CRAN (R 4.0.1) ## CRAN (R 4.0.0) ## CRAN (R 4.0.0) ## CRAN (R 4.0.2) ## CRAN (R 4.0.1) ## CRAN (R 4.0.2) ## CRAN (R 4.0.2) ## CRAN (R 4.0.0) ## CRAN (R 4.0.2) ## Github (ropensci/tabulizer@fa4dff5) ## Github (ropensci/tabulizerjars@d1924e0) ## CRAN (R 4.0.2) ## CRAN (R 4.0.1) ## CRAN (R 4.0.1) ## CRAN (R 4.0.1) ## CRAN (R 4.0.1) ## CRAN (R 4.0.2) ## CRAN (R 4.0.1) ## CRAN (R 4.0.0) ## CRAN (R 4.0.2) ## CRAN (R 4.0.3) ## CRAN (R 4.0.0) ## CRAN (R 4.0.0) ## ## [1] /home/alexis/R/x86_64-pc-linux-gnu-library/4.0 ## [2] /usr/local/lib/R/site-library ## [3] /usr/lib/R/site-library ## [4] /usr/lib/R/library "],["références.html", "Références", " Références Allaire, JJ, Yihui Xie, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, Hadley Wickham, Joe Cheng, Winston Chang, et Richard Iannone. 2020. Rmarkdown: Dynamic Documents for R. https://github.com/rstudio/rmarkdown. Healy, K. 2018. Data Visualization: A Practical Introduction. Princeton University Press. https://kieranhealy.org/publications/dataviz/. Henry, Lionel, et Hadley Wickham. 2020. Purrr: Functional Programming Tools. https://CRAN.R-project.org/package=purrr. Hoang, L. N. 2018. La Formule du Savoir: Une philosophie unifiée du savoir fondée sur le théorème de Bayes. HORS COLLECTION. EDP sciences. https://books.google.fr/books?id=6xdgDwAAQBAJ. Lovelace, R., J. Nowosad, et J. Muenchow. 2019. Geocomputation with R. Chapman &amp; Hall/CRC The R Series. CRC Press. https://geocompr.robinlovelace.net/. R Core Team. 2020. R: A Language and Environment for Statistical Computing. Vienna, Austria : R Foundation for Statistical Computing. https://www.R-project.org/. Wickham, Hadley. 2014. « Tidy Data ». Journal of Statistical Software 59 (10). https://doi.org/10.18637/jss.v059.i10. Wickham, H., et G. Grolemund. 2016. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. O’Reilly Media. https://r4ds.had.co.nz/. Xie, Yihui. 2014. « Knitr: A Comprehensive Tool for Reproducible Research in R ». Dans Implementing Reproducible Computational Research. Sous la direction de Victoria Stodden, Friedrich Leisch, et Roger D. Peng. Chapman; Hall/CRC. http://www.crcpress.com/product/isbn/9781466561595. ———. 2015. Dynamic Documents with R and knitr. 2nd éd. Boca Raton, Florida : Chapman; Hall/CRC. https://yihui.org/knitr/. ———. 2020. Knitr: A General-Purpose Package for Dynamic Report Generation in R. https://yihui.org/knitr/. Xie, Yihui, J. J. Allaire, et Garrett Grolemund. 2018. R Markdown: The Definitive Guide. Boca Raton, Florida : Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown. Xie, Yihui, Christophe Dervieux, et Emily Riederer. 2020. R Markdown Cookbook. Boca Raton, Florida : Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown-cookbook. "]]
