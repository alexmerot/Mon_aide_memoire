# Extraction/importation, nettoyage & manipulation des données {#data-analysis}

::: {.infobox .caution data-latex="{caution}"}
*_Work In Progress_*
:::

<!-- TODO : Ajouter l'analyse exploratoire des données -->

## Extraction de données provenant d'un PDF

Il existe plusieurs packages sous R permettant de manipuler les PDF. Pour en
extraire le texte et les métadonnées, il y a le package
[`pdftools`](https://github.com/ropensci/pdftools). Néanmoins, pour pouvoir
extraire plus particulièrement les données des tableaux, il existe le package
[`tabulizer`](https://github.com/ropensci/tabulizer) qui sert de lien à la
bibliothèque java [Tabula](https://github.com/tabulapdf/tabula-java/). C'est ce
package que je vais utiliser pour pouvoir extraire les données d'un PDF.

```{r, message=FALSE, warning=FALSE}
library("tabulizer")
```

Pour montrer l'utilisation de ce package, je vais utiliser pour exemple un
[PDF](https://www.rnn-hautechainedujura.fr/composants/uploads/2020/04/Entomofaune-PG3.pdf)
téléchargé sur le
[site](https://www.rnn-hautechainedujura.fr/patrimoine-naturel/faune/) de la
[Réserve Naturelle Nationale (RNN) de la Haute Chaîne du
Jura](https://www.rnn-hautechainedujura.fr/). Ce fichier contient des tableaux
montrant les données de recensement pour le plan de gestion 2019-2020 de la
faune présente.

```{r}
# Chemin d'accès au PDF
pdf_data_jura <- "examples/faune-RNN-jura/Faune-vertebres-PG3.pdf"
```

Pour extraire les données, il faut utiliser la fonction `extract_tables`. Cette
fonction renvoie par défaut une matrice ou une liste de matrices s'il y a
plusieurs tableaux. On peut renvoyer directement un `data.frame` en ajoutant le
paramètre `output = "data.frame"`. Cependant, lors de la tentative de
conversion, la structure du tableau peut ne pas correspondre au jeu de données
réel. Je garde donc ici la sortie en matrice, puis je transforme ces matrices en
`data.frame`. Vu qu'il y a plusieurs tableaux, la fonction `extract_tables` va
sortir une liste de matrices. J'utilise donc la fonction `map` du package
[`purrr`](https://purrr.tidyverse.org/) pour appliquer la fonction
`as.data.frame` de manière récursive sur tous les éléments de la liste. Ce
package permet d'améliorer la partie programmation fonctionnelle dans R,
notamment en remplaçant la plupart des boucles `for`. Le code devient ainsi plus
succinct et plus facile à lire, tout en gardant son efficacité.

```{r, eval=FALSE}
jura_data <- extract_tables(pdf_data_jura) %>% 
  purrr::map(as.data.frame)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
jura_data <- readRDS("examples/faune-RNN-jura/jura_data.RDS")
```

On peut ensuite vérifier que les tableaux correspondent à ce que l'on peut voir
sur le PDF. Par exemple, on peut regarder les dimensions des tableaux à l'aide
de la fonction `dim`.

```{r, collapse=TRUE}
purrr::map(jura_data, dim)
```

On peut déjà voir qu'il y a 4 tableaux au lieu de 3. C'est dû au fait que le
3^ème^ tableau est séparé sur deux pages. De plus, les tableaux 1 et la première
partie du 3 contiennent une colonne en trop (respectivement 15 au lieu de 14 et
16 au lieu de 15).

Regardons alors de plus près ce que contiennent ces tableaux :

```{r}
# Récupération du nom des tableaux dans la liste.
tableau <- purrr::map(1:length(jura_data), ~ glue::glue("jura_data[[{.}]]"))

# Récupération des dimensions des tableaux
dimensions <- purrr::map(jura_data, dim) %>%
  purrr::map(~ glue::glue("{.[[1]]} lignes et {.[[2]]} colonnes")) %>%
  unlist()

# Création d'un tableau interactif contenant l'ensemble des jeux de données.
all_output <- my_reactable(
  data.frame(tableau = unlist(tableau), dimensions),
  details = function(index) {
    htmltools::div(
        my_reactable(
          jura_data[[index]],
          fullWidth = FALSE,
          pagination = FALSE,
          outlined = TRUE,
          compact = TRUE,
          height = 500,
          showPageSizeOptions = FALSE,
          showPageInfo = FALSE
        )
    )
  },
  defaultPageSize = length(tableau), 
  minRows = length(tableau),
  onClick = "expand",
  rowStyle = list(cursor = "pointer"),
  rownames = FALSE,
  defaultColDef = colDef(na = "")
)
```
<br>

<caption>(#tab:juradata) Tableaux contenant les données brutes extraites du PDF (cliquer pour étendre les tableaux). </caption>

```{r, echo=FALSE}
all_output
```
<br>

Si on regarde les valeurs uniques des colonnes en trop pour `jura_data[[1]]` et
`jura_data[[3]]`, on s'aperçoit que la colonne du premier tableau est vide
(`""`), tandis que pour l'autre il y a la présence d'un `"1"`.

```{r}
unique(jura_data[[1]][, 15])
unique(jura_data[[3]][, 16])
```

On peut donc regarder la ligne où il y a l'erreur :

```{r}
line_id <- which(jura_data[[3]][, 16] == "1")

my_reactable(
  jura_data[[3]][line_id,],
  height = "auto",
  filterable = FALSE,
  defaultPageSize = 1, 
  minRows = 1
)
```

La ligne qui en ressort est celle pour le Grand Tétras. En comparant avec la
ligne du tableau sur le PDF, on peut se rendre compte qu'il y a un décalage à
partir de la colonne de la Directive Oiseaux Annexe 1. Cela peut être dû à la
mauvaise visualisation de la puce (bien présente) à la colonne
"Protection nationale". Cette puce ne semble pas visible, mais en surlignant
avec la souris le texte de cette case, on peut voir apparaître la puce "•". On
peut donc réécrire correctement cette ligne d'après le PDF :

```{r}
# Modification de la ligne posant problème.
jura_data[[3]][line_id,] <- list(
  "Tetrao urogallus major C. L. Brehm, 1831",
  "Grand Tétras",
  "2018",
  "oui",
  "oui",
  "VU",
  "CR",
  "oui",
  NA,
  "oui",
  NA,
  "En déclin",
  "Forte",
  "Forte",
  "1",
  ""
)
```

Maintenant que cela est fait, on peut également observer qu'il faut nettoyer ces
jeux de données. En effet, il faut d'abord mettre la première ligne en tant que
nom des colonnes (fonction `janitor::row_to_names`). Ensuite il faut modifier
les noms des colonnes pour les standardiser et être plus facilement utilisables
dans les scripts (fonction `janitor::clean_names`). Il faut aussi rajouter des
`NA` dans les cases vides (fonction `dplyr::na_if`). Les lignes et colonnes
entièrement vides peuvent être supprimées (fonction `janitor::remove_empty`).
Enfin, les puces typographiques "•" qui représentent la valeur booléenne `TRUE`
doivent être remplacées par exemple par "oui", pour que ces colonnes soient plus
facilement manipulables (fonctions `dplyr::mutate` et `dplyr::across`).

Pour ce faire, je crée une fonction pour que le code soit facilement
réutilisable (et applicable dans la fonction `purrr::map`) :

```{r}
clean_extracted_data <- function(data_extracted) {
  cleaned_df <- data_extracted %>%
    janitor::row_to_names(1) %>%
    janitor::clean_names()
  
  # Création de la fonction qui remplacera les puces typographiques.
  replace_bullet <- function(x) {
    if (is.na(x)) {
      output = x
    } else {
      if (x == "•") {
        output = "oui"
      } else if (x == "") {
        output = "non"
      } else {
        output = x
      }
    }
    
    return(output)
  }
  
  cleaned_df <- cleaned_df %>%
    # Pour chaque colonne ayant les puces, on les remplace.
    mutate(across(where(~ any(grepl("•", .))), ~ purrr::map_chr(., replace_bullet))) %>%
    ungroup() %>%
    # Pour les colonnes où les cases vides ne représentent pas des NA, on les
    # remplacent par "—".
    mutate(across(starts_with(c("lr_", "ec_")), ~ ifelse(. == "", "—", .))) %>%
    na_if("") %>% # On remplace les cases vides restantes par des NA.
    janitor::remove_empty(c("rows", "cols")) # Suppression des lignes et colonnes vides
  
  rownames(cleaned_df) <- NULL # Actualisation des numéros de ligne
  
  return(cleaned_df)
}
```

Ensuite, il ne reste plus qu'à appliquer cette fonction sur les tableaux
extraits :

```{r}
jura_data_cleaned <- jura_data %>% purrr::map(clean_extracted_data)
```

Les tableaux ressemblent maintenant à cela :

<caption>(#tab:juradatacleaned) Tableaux contenant les données extraites du PDF et nettoyées (cliquer pour étendre les tableaux). </caption>

```{r, echo=FALSE}
# Récupération du nom des tableaux dans la liste.
tableau <- purrr::map(
  1:length(jura_data_cleaned),
  ~ glue::glue("jura_data_cleaned[[{.}]]")
)

# Récupération des dimensions des tableaux
dimensions <- purrr::map(jura_data_cleaned, dim) %>%
  purrr::map(~ glue::glue("{.[[1]]} lignes et {.[[2]]} colonnes")) %>%
  unlist()

# Création d'un tableau interactif contenant l'ensemble des jeux de données.
all_output <- my_reactable(
  data.frame(tableau = unlist(tableau), dimensions),
  details = function(index) {
    htmltools::div(
        my_reactable(
          jura_data_cleaned[[index]],
          fullWidth = FALSE,
          pagination = FALSE,
          outlined = TRUE,
          compact = TRUE,
          height = 500,
          showPageSizeOptions = FALSE,
          showPageInfo = FALSE
        )
    )
  },
  searchable = FALSE,
  defaultPageSize = length(tableau), 
  minRows = length(tableau),
  onClick = "expand",
  rowStyle = list(cursor = "pointer"),
  rownames = FALSE,
  defaultColDef = colDef(na = "")
)

all_output
```
<br>

On peut maintenant fusionner les deux sous-parties du tableau 3 (tableaux
`jura_data_cleaned[[3]]` et `jura_data_cleaned[[4]]`) et visualiser les tableaux
finaux :

```{r}
herpetofaune_jura <- jura_data_cleaned[[1]]
mammiferes_jura <- jura_data_cleaned[[2]]
avifaune_jura <- bind_rows(jura_data_cleaned[[3]], jura_data_cleaned[[4]])
```

<caption>(#tab:herpetofaune-jura)Données présentant l'herpétofaune de la Réserve Naturelle Nationale de la Haute Chaîne du Jura.</caption>

```{r, echo=FALSE}
my_reactable(herpetofaune_jura)
```
<br>

<caption>(#tab:mammifere-jura)Données présentant les mammifères de la Réserve Naturelle Nationale de la Haute Chaîne du Jura.</caption>

```{r, echo=FALSE}
my_reactable(mammiferes_jura)
```
<br>

<caption>(#tab:avifaune-jura)Données présentant l'avifaune de la Réserve Naturelle Nationale de la Haute Chaîne du Jura.</caption>

```{r, echo=FALSE}
my_reactable(avifaune_jura)
```
<br>

## Récupération de données provenant du web : le _web scraping_

Le _web scraping_ est une technique permettant d'extraire, le plus souvent de
façon automatique, le contenu d'une page web. Cela peut être très utile pour
récupérer des données publiques nécessaires à nos analyses. Internet est un
puits de connaissance, il faut donc en profiter et puiser ses ressources.
[Wikipédia](https://fr.wikipedia.org/wiki/Wikip%C3%A9dia:Accueil_principal)
peut être parfait pour cela.

Sous R, le package permettant de parcourir et de récupérer facilement le contenu
d'une page web s'appelle [`rvest`](https://github.com/tidyverse/rvest).

<!-- TODO : Utiliser le package `polite` avec `rvest`  -->
```{r, message=FALSE, warning=FALSE}
library("rvest")
```

Ici, mon but est de récupérer la classification des différentes espèces
d'oiseaux de la Réserve Naturelle Nationale de la Haute Chaîne du Jura (tableau
\@ref(tab:avifaune-jura)). Cette classification peut être facilement récupérée
sur les pages Wikipédia des oiseaux en question. Je veux donc créer une fonction
qui va rechercher la page Wikipédia de l'oiseau voulu, puis récupérer sous la
forme d'un tableau sa classification.

```{r}
get_bird_classification <- function(bird, taxon = c("Ordre", "Famille")) {
  wiki_link <- "https://fr.wikipedia.org/wiki/Wikip%C3%A9dia:Accueil_principal"
  
  # On ouvre une session sur la page d'accueil de Wikipédia
  session <- html_session(wiki_link)
  
  # On écrit dans la barre de recherche le nom de l'oiseau
  form <- html_form(session)
  form_modified <- set_values(form[[1]], search = bird)
  
  # On entre sur la page wikipédia de l'oiseau
  wiki_bird <- submit_form(session, form_modified, submit = "go")
  
  tbl_classification <- wiki_bird %>%
    # On récupère le nœud HTML contenant le tableau
    html_node(xpath = "//table[@class='taxobox_classification']") %>%
    # On extrait le tableau
    html_table() %>%
    # Puis on met en forme ce tableau
    magrittr::set_colnames(c("niveau_classification", "nom_classification")) %>%
    filter(niveau_classification %in% taxon) %>%
    tidyr::pivot_wider(
      names_from = niveau_classification,
      values_from = nom_classification
    )
  
  tbl_classification$nom <- bird
  
  return(tbl_classification)
}
```

La fonction ainsi créée est utilisée sur les noms latin extraits du PDF. Pour
enlever les noms de découvreur des espèces (exemple : « (Linnaeus, 1758) »),
j'utilise une expression régulière qui identifie l'espèce et le genre des
oiseaux (ça extrait les deux premiers mots de la chaîne de caractères).

```{r, eval=FALSE}
noms_latin <- stringr::str_extract_all(avifaune_jura$nom_latin, r"(^\w+\s+\w+)")

classification_oiseaux <- purrr::map(noms_latin, get_bird_classification) %>%
  bind_rows() # Fusion des tableaux
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
avifaune_jura <- readr::read_csv("examples/webscraping/classification_avifaune.csv", na = "")
```


Je fusionne ensuite le 1^er^ tableau avec le tableau récupéré par *web
scraping*.

```{r, eval=FALSE}
avifaune_jura <- avifaune_jura %>%
  mutate(nom = unlist(noms_latin)) %>%
  left_join(classification_oiseaux, by = "nom") %>%
  select(-nom) %>%
  relocate(Ordre:last_col())
```

<br>

<caption>(#tab:avifaune-famille)Données présentant l'avifaune de la Réserve Naturelle Nationale de la Haute Chaîne du Jura. Ces données ont été regroupées selon l'ordre et la famille des espèces présentes. (Cliquer pour étendre.)</caption>

```{r, echo=FALSE, message=FALSE, warning=FALSE}
downloadthis::download_file(
  path = "examples/webscraping/classification_avifaune.csv",
  output_name = "classification_avifaune", 
  button_label = "Télécharger au format CSV",
  has_icon = TRUE,
  icon = "fa fa-save",
  class = "hvr-sweep-to-left"
)
```

```{r, echo=FALSE}
my_reactable(
  avifaune_jura,
  groupBy = c("Ordre", "Famille"),
  height = "600",
  rownames = FALSE,
  defaultExpanded = TRUE,
  columns = list(
    Ordre = colDef(
      class = "sticky left-col-1",
      headerClass = "sticky left-col-1",
    ),
    Famille = colDef(
      class = "sticky left-col-2",
      headerClass = "sticky left-col-2"
    ),
    nom_latin = colDef(
      class = "sticky left-col-3",
      headerClass = "sticky left-col-3"
    ),
    lr_nationale_2016_des_oiseaux_nicheurs = colDef(
      style = function(value) {
        colour <- "#1e74a2"
        if (value == "NA") colour <- "#ffffff"
        if (value == "—") colour <- "#d0cece"
        if (value == "LC") colour <- "#a9d08e"
        if (value == "NT") colour <- "#fce4d6"
        if (value == "VU") colour <- "#ffd966"
        if (value == "EN") colour <- "#ff9900"
        if (value == "CR") colour <- "#ff3300"
        
        list(background = colour, fontWeight = "bold", color = "#000000")
      }
    ),
    lr_ra_2008 = colDef(
      style = function(value) {
        colour <- "#1e74a2"
        if (value == "NA") colour <- "#ffffff"
        if (value %in% c("DDm", "DD")) colour <- "#ffffff"
        if (value == "—") colour <- "#d0cece"
        if (value %in% c("LC", "LCm")) colour <- "#a9d08e"
        if (value == "NT") colour <- "#fce4d6"
        if (value %in% c("VU", "VUm", "Vum")) colour <- "#ffd966"
        if (value == "EN") colour <- "#ff9900"
        if (value == "CR") colour <- "#ff3300"
        
        list(background = colour, fontWeight = "bold", color = "#000000")
      }
    ),
    ec_do_pop_nicheuse = colDef(
      style = function(value) {
        colour <- "#1e74a2"
        if (value == "NA") colour <- "#ffffff"
        if (value %in% c("Fluctuantes", "Inconnues")) colour <- "#ffffff"
        if (value == "—") colour <- "#d0cece"
        if (value == "En amélioration") colour <- "#a9d08e"
        if (value == "Stable") colour <- "#ffd966"
        if (value == "En déclin") colour <- "#ff3300"

        list(background = colour, fontWeight = "bold", color = "#000000")
      }
    ),
    valeur_patrimoniale = colDef(
      style = function(value) {
        colour <- "#1e74a2"
        if (value == "Faible") colour <- "#fff2cc"
        if (value == "Moyenne") colour <- "#ffd966"
        if (value == "Forte") colour <- "#ff3300"

        list(background = colour, fontWeight = "bold", color = "#000000")
      }
    ),
    responsabilite_rnn = colDef(
      style = function(value) {
        colour <- "#1e74a2"
        if (value == "Faible") colour <- "#fff2cc"
        if (value == "Moyenne") colour <- "#ffd966"
        if (value == "Forte") colour <- "#ff3300"
        
        list(background = colour, fontWeight = "bold", color = "#000000")
      }
    ),
    priorite_de_conservation = colDef(
      style = function(value) {
        colour <- "#1e74a2"
        if (value == "1") colour <- "#fff2cc"
        if (value == "2") colour <- "#ffd966"
        if (value == "3") colour <- "#ff3300"
        
        list(background = colour, fontWeight = "bold", color = "#000000")
      }
    )
  ),
  defaultColDef = colDef(
    footerStyle = list(
      fontWeight = "bold",
      background = "hsl(52, 4%, 47%)",
      color = "#000000")
  )
)

```

```{css, echo=FALSE}
.sticky {
  position: sticky !important;
  background: hsl(233, 9%, 19%);
  z-index: 1;
}

.left-col-1 {
  left: 0;
}

.left-col-2 {
  left: 100px;
}

.left-col-3 {
  left: 200px;
  border-right: 1px solid hsl(233, 9%, 22%) !important;
}
```


<br>

## Liste de ressources Internet utiles {.unnumbered #ref-data-analysis}

* Courte comparaison entre [les deux
packages](https://thinkr.fr/tm-ou-tidytext-introduction-au-text-mining-avec-r/)
de _text mining_ dans R.
* Introduction au [_tidy text mining_](https://www.tidytextmining.com/).
* [Introduction](https://cran.r-project.org/web/packages/tabulizer/vignettes/tabulizer.html) au package [`tabulizer`](https://github.com/ropensci/tabulizer).
* [Tutoriel](https://datascienceplus.com/extracting-tables-from-pdfs-in-r-using-the-tabulizer-package/)
sur l'utilisation du package `tabulizer`.
* Autre [tutoriel](https://blog.az.sg/posts/reading-pdfs-in-r/) sur `tabulizer`.
* [Catalogue](https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html)
des fonctions du package `janitor` pour l'exploration et le nettoyage des données.
* [Introduction](https://cran.r-project.org/web/packages/naniar/vignettes/getting-started-w-naniar.html)
du package `naniar` pour la manipulation des valeurs manquantes.
